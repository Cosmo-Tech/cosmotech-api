management:
  endpoints:
    enabled-by-default: false

spring:
  data:
    redis:
      host: "localhost"
      username: "default"
      # Leave it as blank as there's no auth with test container
      password:
      client-type: jedis
    aws:
      credentials:
        access-key: "s3_username"
        secret-key: "s3_password"
      s3:
        region: "dummy"
        path-style-access-enabled: true
        endpoint: "http://localhost:9000"
  main:
    banner-mode: "off"

csm:
  platform:
    runOutsideKubernetes: true
    metrics:
      enabled: false
    api:
      # API Base Path for OpenAPI-generated controllers.
      # Might conflict with the SpringBoot context path, hence leaving it at the root
      base-path: /
      base-url: "http://fake_url:8080"
      version: latest
    id-generator:
      type: hashid
    event-publisher:
      type: in_process
    images:
      scenario-fetch-parameters: cosmo-tech/fetch-scenario-parameters
      send-datawarehouse: cosmo-tech/azure-data-explorer-connector
      scenario-data-upload: cosmo-tech/azure-storage-publish:latest
    containers:
      - name: "ADTTwingraphImport"
        imageRegistry: "ghcr.io"
        imageName: "cosmo-tech/adt-twincache-connector"
        imageVersion: "0.0.5"
      - name: "StorageTwingraphImport"
        imageRegistry: "ghcr.io"
        imageName: "cosmo-tech/azstorage-twincache-connector"
        imageVersion: "latest"
    upload:
      authorized-mime-types:
        workspaces:
          - application/zip
          - application/xml
          - application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
          - application/x-tika-ooxml
          - text/csv
          - text/plain
          - text/x-yaml
          - application/json
    authorization:
      tenant-id-jwt-claim: "iss"
      # Note that the way @Value works in Spring does not make it possible to inject this sole YAML list.
      # Use CsmPlatformProperties instead !
      allowed-tenants: ["test"]
    argo:
      base-uri: "https://argo-server.argo.svc.cluster.local:2746"
      workflows:
        namespace: phoenix
        node-pool-label: ""
        service-account-name: workflowcsmv2
        storage-class: null
        access-modes:
          # Any in the following list: ReadWriteOnce, ReadOnlyMany, ReadWriteMany, ReadWriteOncePod (K8s 1.22+)
          - ReadWriteOnce
        requests:
          storage: 1Gi
    twincache:
      host: "localhost"
      port: "6379"
      username: "default"
      # Leave it as blank as there's no auth with test container
      password:
      connector:
        default-page-size: 5
    rbac:
      enabled: true
    s3:
      region: "dummy"
      endpointUrl: "http://localhost:9000"
      bucketName: "test-bucket"
      accessKeyId: "s3_username"
      secretAccessKey: "s3_password"


